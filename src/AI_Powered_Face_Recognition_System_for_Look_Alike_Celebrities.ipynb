{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **This project implements an AI-based face recognition system that identifies celebrities who resemble the person in a given image. It utilizes a Convolutional Neural Network (CNN) trained on a dataset of celebrity images to compute similarity scores between the input image and known celebrities.**"
      ],
      "metadata": {
        "id": "li7cweDGabUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **First of All**, The following packages are necessary to run the generated project on Google Colab:\n",
        "\n",
        "### **opencv-python:** For image processing tasks like resizing, background removal, and visualization.\n",
        "### **keras**: As a high-level API for building and training neural networks.\n",
        "### **tensorflow**: The underlying framework for Keras, providing essential building blocks for deep learning models.\n",
        "### **deepface**: A library specifically designed for deep learning-based face analysis tasks, including face recognition.\n",
        "### **imutils**: A set of convenience functions for image processing tasks.\n",
        "### **tqdm**: A progress bar library to visualize the progress of long-running operations.\n",
        "### **scikit-learn**: A machine learning library for tasks like preprocessing, model evaluation, and data analysis."
      ],
      "metadata": {
        "id": "-ypetdNDUulE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um52HHb1USEu"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python keras tensorflow deepface imutils tqdm scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1) Prepare the Data and Images**"
      ],
      "metadata": {
        "id": "qGyUt8wHVLXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Data Path Configuration\n",
        "data_dir = '/content/drive/MyDrive/celebrities_photos_jpeg_only'\n",
        "labels_dir = \"/content/drive/MyDrive/My_look_alike_celebrities_model_completed/labels\"\n",
        "\n",
        "# Function to remove background (optional, explore alternative methods)\n",
        "def remove_background(image):\n",
        "    \"\"\"\n",
        "    This function attempts to remove the background from an image using basic thresholding.\n",
        "    Consider exploring more advanced background removal techniques (e.g., segmentation models)\n",
        "    if needed for your specific dataset.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
        "        thresh_inv = cv2.bitwise_not(thresh)\n",
        "        contours, _ = cv2.findContours(thresh_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        max_contour = max(contours, key=cv2.contourArea)\n",
        "        mask = np.zeros_like(gray)\n",
        "        cv2.drawContours(mask, [max_contour], -1, (255), thickness=cv2.FILLED)\n",
        "        person_only = cv2.bitwise_and(image, image, mask=mask)\n",
        "        return person_only\n",
        "    except Exception as e:\n",
        "        print(f\"Background removal exception: {e}\")\n",
        "        return image\n",
        "\n",
        "# Function to create labels database\n",
        "def create_labels_db(labels, file_name):\n",
        "    data = {'Index': [i for i in range(len(labels))], 'Label': labels}\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(labels_dir + \"/\" + file_name, index=False)\n",
        "\n",
        "# Function to generate image paths\n",
        "def get_image_paths(root_dir):\n",
        "    celebrity_paths = [os.path.join(root_dir, subfolder) for subfolder in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, subfolder))]\n",
        "    image_paths = []\n",
        "    for celeb_path in celebrity_paths:\n",
        "        for image in os.listdir(celeb_path):\n",
        "            if image.endswith('.jpg'):\n",
        "                image_path = os.path.join(celeb_path, image)\n",
        "                image_name, _ = os.path.splitext(os.path.basename(image_path))\n",
        "                image_name = ''.join(c for c in image_name if c.isascii())  # Remove non-ASCII characters\n",
        "                image_dir = os.path.dirname(image_path)\n",
        "                new_image_path = os.path.join(image_dir, image_name + \".jpg\")\n",
        "                os.rename(image_path, new_image_path)  # Rename for consistency\n",
        "                image_paths.append(new_image_path)\n",
        "    return image_paths\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    # Consider using background removal if needed\n",
        "    # img = remove_background(img)  # Uncomment if using background removal\n",
        "    img = cv2.resize(img, (128, 128))  # Resize to desired input shape\n",
        "    return img\n",
        "\n",
        "# Load images and labels\n",
        "images = []\n",
        "labels = []\n",
        "for image_path in get_image_paths(data_dir):\n",
        "    try:\n",
        "        img = preprocess_image(image_path)\n",
        "        images.append(img)\n",
        "        label = os.path.basename(os.path.dirname(image_path))[:-1]  # Extract label from directory name\n",
        "        labels.append(label)"
      ],
      "metadata": {
        "id": "KFcB6jwQUtfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`2) Data preparation, model training, and evaluation`**"
      ],
      "metadata": {
        "id": "TLlNMo1OU2Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels database\n",
        "create_labels_db(labels, \"main_labels\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create labels databases for training and testing sets\n",
        "create_labels_db(y_train, \"trained_labels\")\n",
        "create_labels_db(y_test, \"test_labels\")\n",
        "\n",
        "# Convert data to NumPy arrays\n",
        "X_train_resized = np.array(X_train)\n",
        "X_test_resized = np.array(X_test)\n",
        "\n",
        "# Encode labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "\n",
        "# Define the CNN model (adjust architecture as needed)\n",
        "num_classes = len(np.unique(y_train))\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_resized, y_train_encoded, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test_resized, y_test_encoded)\n",
        "\n",
        "# Save the model\n",
        "model_path = '/content/drive/MyDrive/My_look_alike_celebrities_model_completed/models/celebrities22.h5'\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "KvHD3lXRVARq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key improvements of the second Section:**\n",
        "\n",
        "Data Splitting: Clearly separated the dataset into training and testing sets for better evaluation.\n",
        "Label Encoding: Used LabelEncoder to convert categorical labels into numerical values for model training.\n",
        "Model Architecture: Provided a basic CNN architecture as a starting point. You can customize it based on your dataset's complexity and requirements.\n",
        "Training and Evaluation: Included training and evaluation steps to assess the model's performance."
      ],
      "metadata": {
        "id": "XtrbE1hsVbBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Prediction and Visualization**"
      ],
      "metadata": {
        "id": "sgovwY3gWBLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Hyperparameter Tuning**: Experiment with different hyperparameters (e.g., learning rate, batch size, number of epochs) to optimize model performance.\n",
        "**2. Data Augmentation**: Consider techniques like image rotation, flipping, and cropping to increase the dataset's diversity and improve generalization.\n",
        "**3. Model Evaluation Metrics**: Explore additional metrics beyond accuracy (e.g., precision, recall, F1-score) to evaluate the model's performance in different aspects.\n",
        "**4. Deployment**: If satisfied with the results, deploy the model for real-world use.\n",
        "Remember to adjust the code based on your specific dataset and requirements. Experimentation and fine-tuning are essential for building a robust and effective face recognition model."
      ],
      "metadata": {
        "id": "7_NwGIwlbF7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_single_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (128, 128))  # Adjust size as needed\n",
        "    img = np.array(img) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Function to predict similar celebrities\n",
        "def predict_similar_celebrities(image_path, top_n=5):\n",
        "    input_image = preprocess_single_image(image_path)\n",
        "    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "    predictions = model.predict(input_image)\n",
        "    top_indices = np.argsort(predictions[0])[::-1][:top_n]\n",
        "\n",
        "    # Assuming you have a mapping from index to label\n",
        "    label_mapping = {idx: label for idx, label in enumerate(label_encoder.classes_)}\n",
        "\n",
        "    for i, idx in enumerate(top_indices):\n",
        "        label = label_mapping[idx]\n",
        "        # Get image of celebrity (replace with your image data)\n",
        "        celebrity_image = load_celebrity_image(label)  # Assuming you have a function to load celebrity images\n",
        "        celebrity_image = np.asarray(celebrity_image)\n",
        "        celebrity_image = cv2.cvtColor(celebrity_image, cv2.COLOR_BGR2RGB)\n",
        "        plt.subplot(1, top_n, i+1)\n",
        "        plt.imshow(celebrity_image)\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/drive/MyDrive/photos/mohamed_said.jpg'  # Path to input image\n",
        "predict_similar_celebrities(image_path)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LxcrS_1SV1tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Key improvements of the Third Section**:\n",
        "**Function for Preprocessing Single Image**: Added a function to preprocess a single image for prediction.\n",
        "**Label Mapping**: Used label_encoder.classes_ to get the mapping between index and label.\n",
        "**Visualization**: Improved the visualization by displaying the predicted celebrity images along with their labels."
      ],
      "metadata": {
        "id": "2wUfZCb1WbtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Additional Considerations of the Third Section:**\n",
        "\n",
        "**Similarity Metric**: Consider using different similarity metrics (e.g., Euclidean distance) based on your specific requirements.\n",
        "**Model Refinement**: If the results are not satisfactory, experiment with different model architectures, hyperparameters, or data augmentation techniques.\n",
        "**Real-Time Applications**: For real-time applications, optimize the code for speed and consider using a GPU."
      ],
      "metadata": {
        "id": "U-YMpAOkWj0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hjbwdgOdWRyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Additional Features and Enhancements**"
      ],
      "metadata": {
        "id": "k6-q1pstXGIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Predict similar celebrities with similarity scores**"
      ],
      "metadata": {
        "id": "TEfUwjJRZgV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load celebrity images\n",
        "def load_celebrity_image(label):\n",
        "    for img_path in image_paths:\n",
        "        if label in img_path:\n",
        "            return cv2.imread(img_path)  # Load image directly\n",
        "    return None\n",
        "\n",
        "# Function to calculate similarity score\n",
        "def calculate_similarity(input_embedding, celebrity_embedding):\n",
        "    return cosine_similarity(input_embedding.reshape(1, -1), celebrity_embedding.reshape(1, -1))[0][0]\n",
        "\n",
        "# Function to predict similar celebrities with similarity scores\n",
        "def predict_similar_celebrities_with_scores(image_path, top_n=5):\n",
        "    input_image = preprocess_single_image(image_path)\n",
        "    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "    input_embedding = model.predict(input_image)[0]  # Get embedding for input image\n",
        "\n",
        "    celebrity_embeddings = model.predict(np.array(images))  # Get embeddings for all celebrities\n",
        "\n",
        "    similarities = [calculate_similarity(input_embedding, celebrity_embedding) for celebrity_embedding in celebrity_embeddings]\n",
        "    top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
        "\n",
        "    top_labels = [labels[idx] for idx in top_indices]\n",
        "    top_scores = [similarities[idx] for idx in top_indices]\n",
        "\n",
        "    return top_labels, top_scores\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/drive/MyDrive/photos/mohamed_said.jpg'  # Path to input image\n",
        "top_labels, top_scores = predict_similar_celebrities_with_scores(image_path)\n",
        "\n",
        "print(\"Top 3 similar celebrities:\")\n",
        "for label, score in zip(top_labels, top_scores):\n",
        "    print(\"Celebrity:\", label, \"Similarity Score:\", score)"
      ],
      "metadata": {
        "id": "K_RHA5nZXG8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Key improvements of the Fourth Section:**\n",
        "**Celebrity Image Loading**: Directly loads celebrity images using cv2.imread.\n",
        "**Similarity Calculation**: Added a function to calculate the cosine similarity between embeddings.\n",
        "**Prediction with Scores**: Modified the prediction function to return top similar celebrities along with their similarity scores."
      ],
      "metadata": {
        "id": "_YaR5wXiXRi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Additional Considerations of the Fourth Section:**\n",
        "\n",
        "**Feature Extraction**: Experiment with different feature extraction techniques (e.g., pre-trained models like VGGFace) to improve accuracy.\n",
        "**Ensemble Methods**: Consider combining multiple models (e.g., using ensemble techniques like bagging or boosting) to improve performance.\n",
        "**Real-Time Deployment**: For real-time applications, optimize the code for speed and explore GPU acceleration."
      ],
      "metadata": {
        "id": "yrEebjrgXfxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **General Customization**\n",
        "**Dataset**: Replace the dataset path with your own.\n",
        "**Model Architecture**: Experiment with different CNN architectures or pre-trained models.\n",
        "**Hyperparameters**: Tune hyperparameters like learning rate, batch size, and number of epochs.\n",
        "**Evaluation Metrics**: Use additional metrics like precision, recall, and F1-score to evaluate performance."
      ],
      "metadata": {
        "id": "7yNKfhjFXvaH"
      }
    }
  ]
}